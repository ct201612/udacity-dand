
# P5: 从安然公司邮件中发现欺诈证据

## 作者：Chris Tan
### 项目概述

安然曾是 2000 年美国最大的公司之一。2002 年，由于其存在大量的企业欺诈行为，这个昔日的大集团土崩瓦解。 在随后联邦进行的调查过程中，大量有代表性的保密信息进入了公众的视线，包括成千上万涉及高管的邮件和详细的财务数据。

这个项目，我们使用机器学习，根据安然丑闻中公开的财务和邮件数据来对poi进行分类（判断poi是0还是1）。

### 1.	向我们总结此项目的目标以及机器学习对于实现此目标有何帮助。作为答案的部分，提供一些数据集背景信息以及这些信息如何用于回答项目问题。你在获得数据时它们是否包含任何异常值，你是如何进行处理的？【相关标准项：“数据探索”，“异常值调查”】

该项目的目标是通过安然丑闻中公开的财务和邮件数据来对poi进行分类（判断poi是0还是1）；
机器学习算法对于实现此目标帮助：快速处理大量数据集；以下是数据集的背景信息。

#### 雇员
数据集中有146个安然公司雇员，其中18个POIs,128个非POIs。

#### 特征
数据集中每个人有20个特征，1个标签；

数据集中有14个财务特征(单位均是美元）。
- salary
- deferral_payments
- total_payments
- loan_advances
- bonus
- restricted_stock_deferred
- deferred_income 
- total_stock_value
- expenses
- exercised_stock_options
- other
- long_term_incentive
- restricted_stock
- director_fees

数据集中有6个邮箱特征 (单位通常是电子邮件的数量，明显的例外是 ‘email_address’，这是一个字符串）。
- to_messages
- email_address
- from_poi_to_this_person
- from_messages
- from_this_person_to_poi
- shared_receipt_with_poi

POI标签 (boolean，整数)
- poi

####  根据数据集特点定机器学习的策略
- 基于数据的不平衡性，accuracy并不是很好的评估指标，选择precision和recall作为评估度量；
- 因为StratifiedShuffleSplit把数据集打乱顺序，然后划分测试集和训练集，所以基于数据的不平衡性tester.py中使用的交叉验证方式为StratifiedShuffleSplit（我选常用的train_test_split作为对比）；
- 数据样本比较少，因此我们可以使用GridSearchCV来进行参数调整；

#### 特征的缺失值情况
除了POI外，其它20个特征都有缺失值，通过featureFormat函数转换为0。

#### 异常值
- 因为在绘制工资和奖金的散点图中发现一个异常值“TOTAL”，查询数据集后，发现这是一个总工资和奖金的数字，这里把TOTAL也当做了一名员工，所以删除它。
- 查询数据集后，发现“THE TRAVEL AGENCY IN THE PARK”不是一个员工记录，所以删除它。
- 查询数据集后，发现“LOCKHART EUGENE E”没有有用信息，所以删除它。

### 2.	你最终在你的 POI 标识符中使用了什么特征，你使用了什么筛选过程来挑选它们？你是否需要进行任何缩放？为什么？作为任务的一部分，你应该尝试设计自己的特征，而非使用数据集中现成的——解释你尝试创建的特征及其基本原理。（你不一定要在最后的分析中使用它，而只设计并测试它）。在你的特征选择步骤，如果你使用了算法（如决策树），请也给出所使用特征的特征重要性；如果你使用了自动特征选择函数（如 SelectBest），请报告特征得分及你所选的参数值的原因。【相关标准项：“创建新特征”、“适当缩放特征”、“智能选择功能”】
#### 特征选择
我使用SelectKBest函数获得每个特征的分数，我选择K=8，获得8个最高分的特征，用于建模，选择的特征和分数如下：
- 得分高的第1个特征： exercised_stock_options（25.097541528735491)
- 得分高的第2个特征： total_stock_value（24.467654047526398)
- 得分高的第3个特征： bonus（21.060001707536571)
- 得分高的第4个特征： salary（18.575703268041785)
- 得分高的第5个特征： to_poi_ratio（16.641707070468989)
- 得分高的第6个特征： deferred_income（11.595547659730601)
- 得分高的第7个特征： long_term_incentive（10.072454529369441)
- 得分高的第8个特征： restricted_stock（9.3467007910514877)

#### 特征缩放
由于原始数据的范围变化很大，对于大多数机器学习算法（如SVM）和优化算法来说，如果特征都在同一范围内，会获得更好的结果，因此我选择scikit learn中MinMaxScaler将每个特征缩放到同一范围。

#### 创建特征
因为POI之间相互进行邮件联系的可能性比与非POI的要大，因此我创建两个新特征：
- from_poi_ratio：表示员工收到POI邮件的比例；
- to_poi_ratio：表示员工发给POI邮件的比例；

### 3.	你最终使用了什么算法？你还尝试了其他什么算法？不同算法之间的模型性能有何差异？【相关标准项：“选择算法”】
我测试3种算法，并使用scikit-learn的GridSearchCV优化每种算法的参数，结果如下：
#### GaussianNB：
- Precision:  0.408973665224
- Recall:  0.374167388167

#### SVM：
- Precision:  0.146333333333
- Recall:  0.0564523809524

最优参数：
- kernel = 'linear', 
- C = 0.1, 
- gamma = 1

#### DecisionTree：
- Precision:  0.255848706849
- Recall:  0.229024531025

最优参数：
- min_samples_split = 20, 
- class_weight = None, 
- criterion = 'gini', 
- max_depth = None, 
- min_samples_leaf = 5 

最后，因为精确度和召回率两者越高，算法效果越好，所以我使用的算法是GaussianNB（在tester.py评估精确度和召回率都大于3）；

### 4.	调整算法的参数是什么意思，如果你不这样做会发生什么？你是如何调整特定算法的参数的？（一些算法没有需要调整的参数 – 如果你选择的算法是这种情况，指明并简要解释对于你最终未选择的模型或需要参数调整的不同模型，例如决策树分类器，你会怎么做）。【相关标准项：“调整算法”】
调整算法的参数是优化影响模型的参数，使算法性能最优；调整机器学习算法的参数至关重要，因为不同的函数和初始设置会对其性能产生深远的影响。在某些情况下，例如在决策树算法中设置错的min_samples_split和min_samples_leaf，该算法可能会过度拟合。

#### 调整参数
我构建3个算法，并使用GridSearchCV函数为每个算法获得最佳参数：

- Naive Bayes：模型简单，非参数
- SVM: kernel = 'linear', C = 0.1, gamma = 1
- DecisionTree:min_samples_split = 20,class_weight = None,criterion = 'gini',max_depth = None,min_samples_leaf = 5 

### 5.	什么是验证，未正确执行情况下的典型错误是什么？你是如何验证你的分析的？【相关标准项：“验证策略”】
验证是一种评估统计分析、机器学习算法对独立于训练数据的数据集的泛化能力，也就是识别过拟合的风险。

典型错误是由于使用相同的数据进行培训和测试，导致训练集中表现良好，但对于新的数据集预测失败。

验证：对每一种算法进行交叉验证（将数据分解为训练数据和测试数据），我运行了100个随机试验并获得精确度和召回率的平均值。


### 6.	给出至少 2 个评估度量并说明每个的平均性能。解释对用简单的语言表明算法性能的度量的解读。【相关标准项：“评估度量的使用”】
我选择评估度量：精确度和召回率，每个算法的评估度量的平均性能如上所示（见问题3的回答），最好性能的算法是Naive Bayes（Precision:  0.40897&Recall:  0.37417），也是最终选择算法：
#### GaussianNB在tester.py的评估下精确度和召回率：
- Precision:  0.48617	
- Recall:  0.39550

#### 精确度
精确度是对我们预测结果而言的，它表示的是预测为正的样本中有多少是真正的正样本。如精确度为0.40897，预测100个为POI的人中，只有40个是真正的POI，其余60个是误报；

#### 召回率
召回率是对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确。如召回率为0.37417，预测中找到真实POI的37%，漏报真实POI的63%；
